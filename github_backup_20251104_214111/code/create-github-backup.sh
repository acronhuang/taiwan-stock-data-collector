#!/bin/bash

# GitHubå‹å¥½çš„å‚™ä»½ç­–ç•¥ - ä¸åŒ…å«è³‡æ–™åº«äºŒé€²ä½æª”æ¡ˆ
# ä»£ç¢¼ + è³‡æ–™åº«çµæ§‹æè¿° + é‚„åŽŸæŒ‡ä»¤

set -e

BACKUP_DATE=$(date '+%Y%m%d_%H%M%S')
GITHUB_BACKUP_DIR="github_backup_${BACKUP_DATE}"

echo "ðŸš€ å»ºç«‹GitHubå‹å¥½çš„å‚™ä»½..."
echo "å‚™ä»½æ™‚é–“: $(date)"

# 1. å»ºç«‹GitHubå‚™ä»½ç›®éŒ„
mkdir -p "${GITHUB_BACKUP_DIR}"

# 2. è¤‡è£½ä»£ç¢¼ (æŽ’é™¤å¤§æª”æ¡ˆ)
echo "ðŸ“ è¤‡è£½å°ˆæ¡ˆä»£ç¢¼..."
rsync -av --progress \
    --exclude 'node_modules' \
    --exclude 'dist' \
    --exclude '.git' \
    --exclude '*.log' \
    --exclude 'backup_*' \
    --exclude 'old' \
    --exclude '*.bson' \
    --exclude '*.tar.gz' \
    . "${GITHUB_BACKUP_DIR}/code/"

# 3. å»ºç«‹è³‡æ–™åº«çµæ§‹æè¿°
echo "ðŸ“Š ç”Ÿæˆè³‡æ–™åº«çµæ§‹æè¿°..."
mkdir -p "${GITHUB_BACKUP_DIR}/database_schema"

# åŒ¯å‡ºè³‡æ–™åº«çµæ§‹ (ä¸å«è³‡æ–™)
mongodump --db scraper --collection tickers --query '{}' --limit 5 --out "${GITHUB_BACKUP_DIR}/database_schema/"
mongodump --db scraper --collection technicalindicators --query '{}' --limit 5 --out "${GITHUB_BACKUP_DIR}/database_schema/"
mongodump --db scraper --collection marketstats --query '{}' --limit 5 --out "${GITHUB_BACKUP_DIR}/database_schema/"

# 4. å»ºç«‹è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š
mongosh scraper --eval "
print('=== è³‡æ–™åº«å®Œæ•´çµ±è¨ˆ ===');
print('ç”Ÿæˆæ™‚é–“: ' + new Date());
print('');

print('Tickers é›†åˆçµ±è¨ˆ:');
var tickersStats = db.tickers.stats();
printjson({
    count: tickersStats.count,
    size: tickersStats.size,
    avgObjSize: tickersStats.avgObjSize,
    indexes: tickersStats.nindexes
});

print('');
print('Technical Indicators é›†åˆçµ±è¨ˆ:');
var indicatorsStats = db.technicalindicators.stats();
printjson({
    count: indicatorsStats.count,
    size: indicatorsStats.size,
    avgObjSize: indicatorsStats.avgObjSize,
    indexes: indicatorsStats.nindexes
});

print('');
print('Market Stats é›†åˆçµ±è¨ˆ:');
var marketStats = db.marketstats.stats();
printjson({
    count: marketStats.count,
    size: marketStats.size,
    avgObjSize: marketStats.avgObjSize,
    indexes: marketStats.nindexes
});

print('');
print('è³‡æ–™ç¯„åœçµ±è¨ˆ:');
print('Tickers æ—¥æœŸç¯„åœ: ' + db.tickers.findOne({}, {date: 1, _id: 0}).date + ' åˆ° ' + db.tickers.find({}, {date: 1, _id: 0}).sort({date: -1}).limit(1).toArray()[0].date);
print('ç¸½è‚¡ç¥¨æ•¸: ' + db.tickers.distinct('symbol').length);
print('ç¸½äº¤æ˜“æ‰€: ' + JSON.stringify(db.tickers.distinct('exchange')));
" > "${GITHUB_BACKUP_DIR}/database_schema/database_stats.txt"

# 5. å»ºç«‹è³‡æ–™åº«æ¨£æœ¬è³‡æ–™
echo "ðŸ“ ç”Ÿæˆè³‡æ–™æ¨£æœ¬..."
mongosh scraper --eval "
print('=== è³‡æ–™æ¨£æœ¬ ===');
print('');
print('Tickers æ¨£æœ¬ (æœ€æ–°5ç­†):');
db.tickers.find().sort({date: -1}).limit(5).forEach(printjson);
print('');
print('Technical Indicators æ¨£æœ¬ (æœ€æ–°5ç­†):');
db.technicalindicators.find().sort({date: -1}).limit(5).forEach(printjson);
print('');
print('Market Stats æ¨£æœ¬ (æœ€æ–°5ç­†):');
db.marketstats.find().sort({date: -1}).limit(5).forEach(printjson);
" > "${GITHUB_BACKUP_DIR}/database_schema/sample_data.json"

# 6. å»ºç«‹å®Œæ•´é‚„åŽŸæŒ‡ä»¤
cat > "${GITHUB_BACKUP_DIR}/RESTORE_INSTRUCTIONS.md" << 'EOF'
# å®Œæ•´ç³»çµ±é‚„åŽŸæŒ‡å—

## ç³»çµ±éœ€æ±‚
- Node.js 18+ 
- MongoDB 6.0+
- npmæˆ–yarn

## 1. åŸºç¤Žç’°å¢ƒè¨­ç½®
```bash
# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/acronhuang/taiwan-stock-data-collector.git
cd taiwan-stock-data-collector

# å®‰è£ä¾è³´
npm install

# è¤‡è£½ç’°å¢ƒé…ç½®
cp .env.example .env
# ç·¨è¼¯ .env æª”æ¡ˆï¼Œè¨­ç½®MongoDBé€£æŽ¥å­—ç¬¦ä¸²
```

## 2. MongoDB è¨­ç½®
```bash
# å•Ÿå‹•MongoDB
mongod

# å»ºç«‹è³‡æ–™åº«å’Œç´¢å¼•
mongosh scraper --eval "
  // å»ºç«‹é›†åˆç´¢å¼•
  db.tickers.createIndex({date: 1});
  db.tickers.createIndex({symbol: 1});
  db.tickers.createIndex({exchange: 1});
  db.tickers.createIndex({date: 1, symbol: 1});
  
  db.technicalindicators.createIndex({date: 1});
  db.technicalindicators.createIndex({symbol: 1});
  db.technicalindicators.createIndex({date: 1, symbol: 1});
  
  db.marketstats.createIndex({date: 1});
  db.marketstats.createIndex({type: 1});
"
```

## 3. æ¢å¾©æ­·å²è³‡æ–™ (å¯é¸)
```bash
# ä½¿ç”¨å…§å»ºçš„æ­·å²è³‡æ–™æŠ“å–å·¥å…·
node working-historical-fetch.js

# æˆ–è€…æ‰¹é‡ç²å–ç‰¹å®šå¹´ä»½
node working-historical-fetch.js 2020 2024
```

## 4. å•Ÿå‹•ç³»çµ±
```bash
# ç·¨è­¯å°ˆæ¡ˆ
npm run build

# å•Ÿå‹•æœå‹™
npm start

# æˆ–é–‹ç™¼æ¨¡å¼
npm run start:dev
```

## 5. è¨­ç½®è‡ªå‹•åŒ–æŽ’ç¨‹ (å¯é¸)
```bash
# å®‰è£cronæŽ’ç¨‹
./install-cron.sh

# æˆ–æ‰‹å‹•æ·»åŠ åˆ°crontab
echo "30 17 * * 1-5 cd /path/to/project && node smart-technical-indicators.js" | crontab -
```

## 6. é©—è­‰ç³»çµ±é‹è¡Œ
- è¨ªå• http://localhost:3001 æª¢æŸ¥API
- è¨ªå• http://localhost:3001/analysis æŸ¥çœ‹åˆ†æžé é¢
- æª¢æŸ¥æ—¥èªŒæ–‡ä»¶ç¢ºèªè‡ªå‹•åŒ–é‹è¡Œ

## è³‡æ–™åº«çµ±è¨ˆåƒè€ƒ
åŸºæ–¼2025-11-04çš„å‚™ä»½ï¼š
- Tickers: 2,205,077 ç­†è¨˜éŒ„
- Technical Indicators: 1,506,199 ç­†è¨˜éŒ„  
- Market Stats: 754 ç­†è¨˜éŒ„
- è¦†è“‹æœŸé–“: 2001-2025å¹´
- æ”¯æ´äº¤æ˜“æ‰€: TWSE, TPEx

## æ•…éšœæŽ’é™¤
1. MongoDBé€£æŽ¥å•é¡Œï¼šæª¢æŸ¥.envé…ç½®å’ŒMongoDBæœå‹™ç‹€æ…‹
2. ç«¯å£å ç”¨ï¼šä¿®æ”¹main.tsä¸­çš„ç«¯å£è¨­ç½®
3. æ¬Šé™å•é¡Œï¼šç¢ºä¿è…³æœ¬æœ‰åŸ·è¡Œæ¬Šé™ (chmod +x *.sh)
4. ä¾è³´å•é¡Œï¼šæ¸…é™¤node_modulesä¸¦é‡æ–°å®‰è£

## æ”¯æ´è¯ç¹«
å¦‚é‡å•é¡Œè«‹æŸ¥çœ‹README.mdæˆ–æäº¤issue
EOF

# 7. å»ºç«‹è³‡æ–™åº«å®Œæ•´å‚™ä»½æŒ‡ä»¤ (ç”¨æˆ¶åœ¨æ–°æ©Ÿå™¨ä¸ŠåŸ·è¡Œ)
cat > "${GITHUB_BACKUP_DIR}/create_full_database_backup.sh" << 'EOF'
#!/bin/bash
# åœ¨åŽŸå§‹æ©Ÿå™¨ä¸ŠåŸ·è¡Œæ­¤è…³æœ¬ä¾†å»ºç«‹å®Œæ•´è³‡æ–™åº«å‚™ä»½

echo "å»ºç«‹å®Œæ•´è³‡æ–™åº«å‚™ä»½..."
BACKUP_DATE=$(date '+%Y%m%d_%H%M%S')
BACKUP_FILE="database_full_backup_${BACKUP_DATE}.tar.gz"

# åŒ¯å‡ºå®Œæ•´è³‡æ–™åº«
mongodump --db scraper --out temp_db_backup/

# å£“ç¸®
tar -czf "${BACKUP_FILE}" temp_db_backup/

# æ¸…ç†
rm -rf temp_db_backup/

echo "âœ… å®Œæ•´è³‡æ–™åº«å‚™ä»½å®Œæˆ: ${BACKUP_FILE}"
echo "è«‹å°‡æ­¤æª”æ¡ˆå‚³è¼¸åˆ°æ–°æ©Ÿå™¨ä¸¦åŸ·è¡Œé‚„åŽŸ"

# é‚„åŽŸæŒ‡ä»¤
cat > "restore_${BACKUP_FILE}" << 'RESTORE_EOF'
#!/bin/bash
# é‚„åŽŸå®Œæ•´è³‡æ–™åº«å‚™ä»½

BACKUP_FILE="$1"
if [ -z "$BACKUP_FILE" ]; then
    echo "ä½¿ç”¨æ–¹å¼: $0 <backup_file.tar.gz>"
    exit 1
fi

echo "é‚„åŽŸè³‡æ–™åº«å‚™ä»½: $BACKUP_FILE"
tar -xzf "$BACKUP_FILE"
mongorestore temp_db_backup/
rm -rf temp_db_backup/
echo "âœ… è³‡æ–™åº«é‚„åŽŸå®Œæˆ"
RESTORE_EOF

chmod +x "restore_${BACKUP_FILE}"
echo "é‚„åŽŸè…³æœ¬å·²å»ºç«‹: restore_${BACKUP_FILE}"
EOF

chmod +x "${GITHUB_BACKUP_DIR}/create_full_database_backup.sh"

# 8. å»ºç«‹ç³»çµ±è³‡è¨Š
cat > "${GITHUB_BACKUP_DIR}/SYSTEM_INFO.md" << EOF
# ç³»çµ±å‚™ä»½è³‡è¨Š

## å‚™ä»½è©³æƒ…
- å‚™ä»½æ™‚é–“: $(date)
- åŽŸå§‹æ©Ÿå™¨: $(uname -a)
- Node.jsç‰ˆæœ¬: $(node --version)
- npmç‰ˆæœ¬: $(npm --version)
- MongoDBç‰ˆæœ¬: $(mongosh --version | head -1)

## è³‡æ–™åº«çµ±è¨ˆ
- è³‡æ–™åº«åç¨±: scraper
- Tickers: $(mongosh scraper --quiet --eval "db.tickers.countDocuments()")
- Technical Indicators: $(mongosh scraper --quiet --eval "db.technicalindicators.countDocuments()")
- Market Stats: $(mongosh scraper --quiet --eval "db.marketstats.countDocuments()")

## å‚™ä»½å…§å®¹
1. å®Œæ•´å°ˆæ¡ˆä»£ç¢¼
2. è³‡æ–™åº«çµæ§‹æ¨£æœ¬
3. è©³ç´°é‚„åŽŸæŒ‡å—
4. è‡ªå‹•åŒ–è…³æœ¬
5. ç³»çµ±é…ç½®æª”æ¡ˆ

## æ³¨æ„äº‹é …
- æ­¤å‚™ä»½ä¸åŒ…å«å®Œæ•´è³‡æ–™åº«æ•¸æ“šï¼ˆå› GitHubå¤§å°é™åˆ¶ï¼‰
- ä½¿ç”¨RESTORE_INSTRUCTIONS.mdé€²è¡Œå®Œæ•´ç³»çµ±é‡å»º
- å¯ä½¿ç”¨create_full_database_backup.shåœ¨åŽŸæ©Ÿå™¨å»ºç«‹å®Œæ•´è³‡æ–™åº«å‚™ä»½
EOF

echo "âœ… GitHubå‹å¥½å‚™ä»½å®Œæˆï¼"
echo "å‚™ä»½ä½ç½®: ${GITHUB_BACKUP_DIR}"
echo "å‚™ä»½å¤§å°: $(du -sh ${GITHUB_BACKUP_DIR} | cut -f1)"
echo ""
echo "ä¸‹ä¸€æ­¥: å°‡æ­¤ç›®éŒ„å…§å®¹æŽ¨é€åˆ°GitHub"